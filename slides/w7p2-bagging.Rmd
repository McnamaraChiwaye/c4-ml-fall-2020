---
title: "Bagging"
author: "Daniel Anderson "
date: "Week 7, Class 2 "
output:
  xaringan::moon_reader:
    css: ["default", "uo", "uo-fonts", "hygge", "custom.css"]
    lib_dir: libs
    nature:
      highlightStyle: atelier-dune-light
      highlightLines: true
      countIncrementalSlides: false
      beforeInit: "https://platform.twitter.com/widgets.js"
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(fig.width = 13, 
                      message = FALSE, 
                      warning = FALSE,
                      echo = TRUE,
                      cache = TRUE)

library(tidyverse)

update_geom_defaults('path', list(size = 3, color = "cornflowerblue"))
update_geom_defaults('point', list(size = 5, color = "gray60"))
theme_set(theme_minimal(base_size = 25))
```

# Agenda
* Ensemble models with bagging to increase model performance generally

* Illustrate bagging with trees

---
# Ensemble models
* Build an .ital[ensemble] of models, rather than just one

* Collect predictions from all models

* Collapse information across models for each prediction to obtain an overall prediction


--
### Benefits
* Often lead to more stable and accurate algorithms

* Can help reduce model variance (minimize overfitting)

---
class: inverse center middle
# Bagging
.b[B]ootstrap .b[Agg]regation

---
# Bagging
* Create $b$ bootstrap resamples of the training data

* Apply the given model (often referred to as the .b[base learner]) to each resample

* Regression: Average predictions across resamples 

* Classification: Take the mode of classification predictions .b[or] average classification probabilities, and then make classification decision

---
# Bagging
* Reduces the .b[variance] of an individual model by averaging across many models

* This works well when the .b[base learner] has high variance

  + Decision trees
  + KNN with small $k$


--
* Bagging .ital[does not] work well for algorithms that already have low variance

  + For example, for a very small sample, bagging may help a linear model, but as the sample size grows, the predictions will be nearly identical while increasing computational complexity


--
* "Wisdom of the crowds" effect
  + Guessing the number of jellybeans in a jar

---
background-image:url(https://bradleyboehmke.github.io/HOML/08-bagging_files/figure-html/bagging-multiple-models-1.png)
background-size: contain
# Example across models

---
# How many bags?
Or, put differently, how many bootstrap resamples?

* Typically anywhere from 50-500 will work well

* Datasets with strong predictors will require fewer bags

* Highly noisy data/variable models will likely need more bags


--
### Too many trees
* Not a problem in terms of estimation - only in computational efficiency

---
# Bias-variance tradeoff

* As we saw, a single decision tree has a high likelihood of overfitting to the observed data

* Hyperparameters help with this by:
  - Limiting the depth of the tree (e.g., $n$ within each terminal node)
  - Pruning (using the cost complexity parameter)
  
* Instead, we can .ital[captialize] on the model variance for understanding the overall trends, but then reducing that variance to a stable model through averaging

* Doesn't mean we don't need to tune the model, just that we probably want to start with a pretty complex model

---
background-image:url(https://i.pinimg.com/736x/ae/c9/c7/aec9c7e029e212d47e7c02e1a009252c---hours-anne.jpg)
background-size: contain
class: inverse center middle
### Implementation with tidymodels
<br/>
.Large[[{baguette}](https://github.com/tidymodels/baguette)]

```{r install-baguette, eval = FALSE}
install.packages("baguette")
```

---
# Load data
Let's work with the same data we used w/decision trees

```{r import-data}
library(tidyverse)
full_train <- read_csv(
  here::here("data", "ds-bowl-2019.csv"),
  col_types = cols(.default = col_guess(),
                   accuracy_group = readr::col_factor(
                     levels = as.character(0:3),
                     ordered = TRUE)
                   )
)
```

---
# Create splits

```{r create-splits}
library(tidymodels)
set.seed(4520)
splt <- initial_split(full_train)
train <- training(splt)
cv <- vfold_cv(train)
train
```

---
# Create a simple recipe
* Model formula
* Specify the outcome as a factor

```{r rec}
rec <- recipe(accuracy_group ~ ., data = train) %>% 
  step_mutate(accuracy_group = factor(accuracy_group))
```

---
# Specify a model
* This time, instead of specifying `decision_tree()` to specify our model, we use `baguette::bag_tree()`. 

* Specify the number of bags via the `times` argument when you `set_engine`

--

```{r bag_tree}
library(baguette)
mod <- bag_tree() %>% 
  set_mode("classification") %>% 
  set_args(cost_complexity = 0, min_n = 2) %>% 
  set_engine("rpart", times = 50) # 50 bootstrap resamples #<<
```

---
# Estimate!
I've included timings here too (we'll see why I'm not using **{tictoc}** later)
```{r bagged_tree1}
m1_start <- Sys.time()
m1 <- fit_resamples(mod, rec, cv)
m1_end <- Sys.time()
m1_end - m1_start

show_best(m1, "roc_auc") # our best w/single model was 0.7806637
show_best(m1, "accuracy") # our best w/single model was 0.671
```

---
# How many bags do we really need?

* Write a function to pull the `roc_auc` from a model with $b$ bagged trees

```{r pull-r, options}
small_cv <- vfold_cv(train, v = 2)

pull_auc <- function(b) {
  # specify model
  mod <- bag_tree() %>% 
    set_mode("classification") %>% 
    set_args(cost_complexity = 0, min_n = 2) %>% 
    set_engine("rpart", times = b)
  
  # fit model to full training dataset
  m <- fit_resamples(mod, rec, small_cv)
  
  show_best(m, "roc_auc")
}
```

---
# test function
```{r test-function}
pull_auc(1)
pull_auc(2)
pull_auc(3)
```

---
# Evaluate b

```{r evaluate-b}
library(future)
plan(multisession)

library(tictoc)
tic()
bags <- map_df(seq(1, 200, 15), pull_auc) 
toc()
plan(sequential)
```

---
# Learning curve

```{r auc-curve, fig.height = 6}
bags %>% 
  mutate(b = seq(5, 200, 15)) %>% 
  ggplot(aes(b, mean)) +
  geom_line() +
  geom_point() 
```

---
# We can still tune
```{r tune-bagged-tree}
mod_tune <- bag_tree() %>% 
  set_mode("classification") %>% 
  set_args(cost_complexity = tune(), min_n = tune()) %>% 
  set_engine("rpart", times = 50) 

tree_grid <- grid_max_entropy(cost_complexity(), min_n(), size = 20)

plan(multisession)
tic()
bag_tune <- tune_grid(mod_tune, rec, cv, grid = tree_grid)
toc()
plan(sequential)
```

---
# Best hyper parameters
```{r select-best}
select_best(bag_tune, "roc_auc")
```

--
### Finalize the model

```{r final-bag-mod}
final_mod <- mod_tune %>% 
  finalize_model(select_best(bag_tune, "roc_auc"))
```

---
```{r final-bag-mod-print}
final_mod
```

---
# Test fit

```{r final-fit}
final_fit <- last_fit(final_mod, rec, splt)
collect_metrics(final_fit)
```

* Recall that our best AUC with a single decision tree was 0.78. So we've made significant gains

* Somewhat surprisingly (to me anyway), our overall accuracy is actually worse

  + Generally (in my experience) you'd make a more informed decision based on balancing sensitivity/specificy

---
# Model assessment
As shown, you can still use $k$-fold CV, .b[but]... You have already created bootstrap resamples in your model fitting process!


--
Out-of-bag (OOB) samples are "free" (computationally)


--
If your sample size is sufficiently large (e.g., $n$ > ~1K), using OOB samples to estimate model performance will result in similar estimates to $k$-fold CV


---
# How do we estimate OOB performance?
* Good question - I don't think you can at present, at least not with **{baguette}**

I [filed an issue](https://github.com/tidymodels/baguette/issues/33) requesting this as a feature. 

I don't have any idea if this will be implemented. Note that basically a version of this was implemented previously, but it's since been removed because of incompatibility with one engine (**C5.0**).


--
Let's look at a different approach, using the *random forest* algortithm, but constraining it to fit a bagged tree model.


---
class: inverse center middle
# Using random forests for bagging

---
# Overview
* Random forests include both bagging and a stochastic components to randomly select columns as each tree is built

* The random selection of columns helps decorrelate the trees and is a hyperparameter in the model

* If we set the number of columns to randomly select equal to the number of predictors, the model simplifies to a bagged tree model

* Joe will talk more about this next week. 

* Fitting the model with the [**{ranger}**]() engine allows us to access OOB predicted probabilities, which we can use to calculate our metrics


---
# Basic modeling setup

```{r }
bt_ranger_mod <- rand_forest() %>% 
  set_engine("ranger") %>% 
  set_mode("classification") %>% 
  set_args(mtry = 5, # Specify number of predictors #<<
           trees = 50, # Number of bags #<<
           min_n = 2, # We can only control tree depth; no pruning #<<
           probability = FALSE) # Build a standard classificaiton tree #<<
```

### Note
We can be certain of our number of predictors by checking our recipe. 

```{r }
sum(rec$var_info$role == "predictor")
```

---
# A note on specification

Likely the most obtuse part of the previous was `probability = FALSE`

* The default is `TRUE`, in which case *probability* trees are built, rather than standard classification trees.
* The **functional** difference here is that the predictions from the model when `probability = TRUE` are class probabilities (for each class). When `probability = FALSE` we get the actual class predictions.
* We need actual class predictions to calculate accuracy in a comparable way to **{rpart}**.

---
# Fit the model
Note, I'm trying to *only fit the model once* (which still leads to 100 trees being grown). So I don't want to use something like `fit_resamples()`. Instead, I'll just use `fit()`.


--

Recall that `fit()` does *not* take a recipe object. For example, I would expec the below to work, but it does not.

```{r error = TRUE}
fit(bt_ranger_mod, rec)
```

---
Instead, we have to prep/bake our data first

```{r }
prepped_d <- rec %>% 
  prep() %>% 
  bake(new_data = NULL) # could also say `bake(train)`
```

And now we can fit the model using `fit(model, formula, data)`

```{r }
tic()
bt_ranger_fit <- fit(bt_ranger_mod, 
                     accuracy_group ~ .,
                     prepped_d)
toc()
```

```{r include = FALSE}
elapsed_rf <- round(.Last.value$toc - .Last.value$tic, 3)
elapsed_resamples <- round(as.double(m1_end - m1_start), 3)
```
---
Print the results

```{r }
bt_ranger_fit
```

---
# Comparing results

Our estimated accuracy is $1 - \text{prediction error}$ or `r 1 - bt_ranger_fit$fit$prediction.error`

What did we get when using $k$-fold CV?

```{r }
show_best(m1, metric = "accuracy")
```

The results are *highly* similar, but the approach using OOB samples took only a fraction of the time. Specifically `r elapsed_resamples` minutes for `fit_resamples()`, versus just `r elapsed_rf` seconds for the OOB estimate.

---
# Other metrics
The primary other metric we've been looking at is `roc_auc`. We can estimate this with `yardstick::roc_auc()`, but for that we *need* the class probabilities. Let's re-estimate.

```{r }
bt_ranger_mod2 <- bt_ranger_mod %>% 
  set_args(probability = TRUE)
bt_ranger_fit2 <- fit(bt_ranger_mod2, 
                     accuracy_group ~ .,
                     prepped_d)
```

---
# Extract predictions
We now need to compare the OOB class probabilities with the observed classes.

First, extract the OOB probabilities. Note that in the below I'm transforming the matrix into a tibble.

```{r }
probs <- as_tibble(bt_ranger_fit2$fit$predictions)
probs
```

---
Next add the observed class to this tibble. **Note:** **{ranger}** only fits to cases with observations on the outcome. So we have to eliminate missing data when we add it in. 

```{r }
probs <- probs %>% 
  mutate(observed = na.omit(prepped_d$accuracy_group))
probs
```

---
# Calculate AUC
Finally, we can calculate AUC using `yardstick::roc_auc()`

```{r }
roc_auc(probs, truth = observed, `0`:`3`)
```

---
# Another example
### Regression

```{r load-regression-data}
set.seed(4520)
d <- read_csv(here::here("data",
                         "train.csv")) %>% 
  select(-classification) %>% 
  sample_frac(0.01)

splt_reg <- initial_split(d)
train_reg <- training(splt_reg)
cv_reg <- vfold_cv(train_reg)
```

---
# Create recipe

```{r regression-rec}
rec_reg <- recipe(score ~ ., data = train_reg)  %>% 
  step_mutate(tst_dt = lubridate::mdy_hms(tst_dt),
              time_index = as.numeric(tst_dt)) %>%
  update_role(tst_dt, new_role = "time_index")  %>% 
  update_role(contains("id"), ncessch, new_role = "id vars")  %>% 
  step_novel(all_nominal())  %>% 
  step_unknown(all_nominal())  %>% 
  step_rollimpute(all_numeric(), -all_outcomes(), -has_role("id vars"))  %>% 
  step_medianimpute(all_numeric(), -all_outcomes(), -has_role("id vars"))  %>% # neccessary when date is NA
  step_zv(all_predictors(), freq_cut = 0, unique_cut = 0) 
```

---
# Single tree
Let's first tune an individual tree. In other words, using this recipe, how predictive of a model can we build, using a decision tree?

```{r single-decision-tree-reg}
tune_single_tree <- decision_tree() %>% 
  set_mode("regression") %>% 
  set_engine("rpart") %>% 
  set_args(cost_complexity = tune(),
           min_n = tune())

params <- parameters(cost_complexity(), min_n())
grd <- grid_max_entropy(params, size = 50)
```

---
# Conduct grid search

```{r grid-search-single-tree}
cl <- parallel::makeCluster(parallel::detectCores())

doParallel::registerDoParallel(cl)
single_tree_grid <- tune_grid(
  tune_single_tree,
  rec_reg,
  cv_reg,
  grid = grd
)
parallel::stopCluster(cl)
foreach::registerDoSEQ() # I was getting errors without this

show_best(single_tree_grid, "rmse")
```

---
# Finalize model & evaluate

```{r finalize-single-tree}
single_tree <- tune_single_tree %>% 
  finalize_model(select_best(single_tree_grid, "rmse"))

single_tree_fit <- last_fit(single_tree, rec_reg, splt_reg)
single_tree_fit$.metrics
```

---
# Bagging

### Evaluate how many bags
This time, let's do it with the OOB performance metric, via **{ranger}**

```{r pull_rmse}
# prep/bake data
prepped_reg <- rec_reg %>% 
  prep() %>% 
  bake(new_data = NULL) %>% 
  select(-contains("id"), -ncessch, -tst_dt)

# number of predictors
ncol(prepped_reg) - 1
```

---
# Write a function

```{r }
pull_rmse <- function(b) {
  # specify model
  mod <- rand_forest() %>% 
    set_mode("regression") %>% 
    set_engine("ranger") %>% 
    set_args(mtry = 28,
             min_n = 2,
             trees = b)
  
  # fit model to full training dataset
  m <- fit(mod, score ~ ., prepped_reg)
  
  # Extract RMSE, store as a tibble
  tibble(rmse = sqrt(m$fit$prediction.error))
}
```

---
# Estimate
Note I'm not using parallel processing here and it's still relatively fast.

```{r learning-curve-rmse}
tic()
bags_reg <- map_df(seq(1, 500, 25), pull_rmse) 
toc()
```

---
# plot
```{r plot-rmse-curve, fig.height = 6}
bags_reg %>% 
  mutate(b = seq(1, 500, 25)) %>% 
  ggplot(aes(b, rmse)) +
  geom_line() +
  geom_point() +
  geom_vline(xintercept = 155, color = "magenta", lwd = 1.3)
```

---
# Tune `min_n`

Tuning with OOB metrics requires a bit more "manual" coding. This is basically the same as when evaluating the number of bags needed.

Note that I've used 200 bags just to be overly cautious. 

```{r tune-bag-regression}
tune_min_n <- function(n) {
  mod <- rand_forest() %>% 
    set_mode("regression") %>% 
    set_engine("ranger") %>% 
    set_args(mtry = 28,
             min_n = n,
             trees = 200)
  
  # fit model to full training dataset
  m <- fit(mod, score ~ ., prepped_reg)
  
  # Extract RMSE, store as a tibble
  tibble(rmse = sqrt(m$fit$prediction.error))
}
```

---
```{r }
tic()
optimal_n <- map_df(seq(2, 170, 2), tune_min_n) 
toc()
```

---
# Check learning curve

```{r }
optimal_n %>% 
  mutate(n = seq(2, 170, 2)) %>% 
  ggplot(aes(n, rmse)) +
  geom_line() +
  geom_point() 

optimal_n %>% 
  mutate(n = seq(2, 170, 2)) %>% 
  filter(n > 48 & n < 62)
```

---
# Finalize bagged model

```{r finalize-bagged-tree}
mod <- rand_forest() %>% 
    set_mode("regression") %>% 
    set_engine("ranger") %>% 
    set_args(mtry = 28,
             min_n = 54,
             trees = 200)
final_fit <- last_fit(mod, rec_reg, splt_reg)
final_fit$.metrics[[1]]
```

Not bad! Still not as good as linear regression though... Also remember this is only 1% of the data (and still takes a while to run) and we didn't merge in any new variables like we did with the lab.

---
# Takeaway
* Bagging is a great way to reduce the variance of a base learner, if that learner has high variance

* In other words - take a low bias model, and reduce its variance

* For models like decision trees, bagging will almost always improve performance

--
* If you learn how to estimate OOB performance with {baguette}, please let me know

--
.major-emph-green[But]

--

* Also messes up feature interpretation some...


---
class: inverse center middle

# Feature interpretation

---
# Start w/{baguette}
* Fit model to full training data

```{r baguette-feat-imp}
full_train_fit <- fit(
  final_mod,
  formula = accuracy_group ~ .,
  data = prep(rec) %>% bake(train)
)
```

---
# Variable importance measures
```{r baguette-vip}
full_train_fit
```


---
# Plot
```{r baguette-plot, fig.height = 6}
full_train_fit$fit$imp %>% 
  mutate(term = fct_reorder(term, value)) %>% 
  ggplot(aes(term, value)) +
  geom_col() +
  coord_flip()
```

---
# VIP

At present, **{vip}** and **{pdp}** do not support **{baguette}** models. But they do support **{ranger}** models.

Note that you have to run the model requesting a variable importance measure.

```{r }
mod_importance <- mod %>%
  set_args(importance = "permutation")

full_reg_fit <- fit(mod_importance,
                    score ~ .,
                    prepped_reg)
```

---
# VIP (regression)
```{r}
library(vip)
vip(full_reg_fit$fit)
```

---
# Look at PDP's

```{r eval = FALSE}
library(pdp)
partial(full_reg_fit$fit, 
        train = prepped_reg, 
        pred.var = "enrl_grd", 
        plot = TRUE, 
        plot.engine = "ggplot2")
```

---
```{r echo = FALSE, fig.height = 9}
library(pdp)
partial(full_reg_fit$fit, 
        train = prepped_reg, 
        pred.var = "enrl_grd", 
        plot = TRUE, 
        plot.engine = "ggplot2")
```


---
# Grade and Tag
```{r eval = FALSE}
partial(full_reg_fit$fit, 
        train = prepped_reg,
        pred.var = c("enrl_grd", "tag_ed_fg"), 
        plot = TRUE, 
        plot.engine = "ggplot2")
```

---
```{r echo = FALSE, fig.height = 9}
partial(full_reg_fit$fit, 
        train = prepped_reg,
        pred.var = c("enrl_grd", "tag_ed_fg"), 
        plot = TRUE, 
        plot.engine = "ggplot2")
```

---
# Individual Condional Expectation Plots

```{r update-geom-path-default, include = FALSE, cache = FALSE}
update_geom_defaults('path', list(size = 0.3, color = "gray70"))
```

```{r eval = FALSE}
partial(full_reg_fit$fit, 
        train = prepped_reg,
        pred.var = "enrl_grd", 
        plot = TRUE, 
        plot.engine = "ggplot2", 
        ice = TRUE) #<<
```

---

```{r echo = FALSE, warning = FALSE, fig.height = 9}
partial(full_reg_fit$fit, 
        train = prepped_reg,
        pred.var = "enrl_grd", 
        plot = TRUE, 
        plot.engine = "ggplot2", 
        ice = TRUE) 
```

---
class: inverse center middle
# Next time
Extending bagged trees w/Random Forests


